{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import (train_test_split)\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error as MSE,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    average_precision_score,\n",
    "    log_loss,\n",
    "\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = pd.read_csv(\"data/employee_data.csv\")\n",
    "oversample = SMOTE()\n",
    "encoder = OrdinalEncoder()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"EmployeeCount\", \"EmployeeNumber\", \"Over18\", \"StandardHours\"], axis=1)\n",
    "data[\"first_company\"] = np.where(data.NumCompaniesWorked == 0, 1, 0)\n",
    "data[\"first_role\"] = np.where(data.YearsAtCompany == data.YearsInCurrentRole, 1, 0)\n",
    "data[\"first_manager\"] = np.where(data.YearsWithCurrManager == data.YearsAtCompany, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(encoder.fit_transform(data), columns=encoder.get_feature_names_out())\n",
    "\n",
    "categorical_cols = data.select_dtypes(include=\"object\").columns.tolist()\n",
    "categorical_cols.append(\"Education\")\n",
    "categorical_cols.append(\"EnvironmentSatisfaction\")\n",
    "categorical_cols.append(\"JobInvolvement\")\n",
    "categorical_cols.append(\"JobLevel\")\n",
    "categorical_cols.append(\"JobSatisfaction\")\n",
    "categorical_cols.append(\"PerformanceRating\")\n",
    "categorical_cols.append(\"RelationshipSatisfaction\")\n",
    "categorical_cols.append(\"WorkLifeBalance\")\n",
    "categorical_cols.append(\"StockOptionLevel\")\n",
    "categorical_cols.append(\"first_company\")\n",
    "categorical_cols.append(\"first_role\")\n",
    "categorical_cols.append(\"first_manager\")\n",
    "categorical_cols.append(\"Gender\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].astype(\"category\")\n",
    "    \n",
    "X = data.drop(columns=[\"Staying?\"])\n",
    "y = data[\"Staying?\"]\n",
    "    \n",
    "X_train, X_leftover, y_train, y_leftover = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_leftover, y_leftover, test_size=0.5, stratify=y_leftover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 34 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   Age                       1470 non-null   float64 \n",
      " 1   Staying?                  1470 non-null   float64 \n",
      " 2   BusinessTravel            1470 non-null   float64 \n",
      " 3   DailyRate                 1470 non-null   float64 \n",
      " 4   Department                1470 non-null   float64 \n",
      " 5   DistanceFromHome          1470 non-null   float64 \n",
      " 6   Education                 1470 non-null   category\n",
      " 7   EducationField            1470 non-null   float64 \n",
      " 8   EnvironmentSatisfaction   1470 non-null   category\n",
      " 9   Gender                    1470 non-null   category\n",
      " 10  HourlyRate                1470 non-null   float64 \n",
      " 11  JobInvolvement            1470 non-null   category\n",
      " 12  JobLevel                  1470 non-null   category\n",
      " 13  JobRole                   1470 non-null   float64 \n",
      " 14  JobSatisfaction           1470 non-null   category\n",
      " 15  MaritalStatus             1470 non-null   float64 \n",
      " 16  MonthlyIncome             1470 non-null   float64 \n",
      " 17  MonthlyRate               1470 non-null   float64 \n",
      " 18  NumCompaniesWorked        1470 non-null   float64 \n",
      " 19  OverTime                  1470 non-null   float64 \n",
      " 20  PercentSalaryHike         1470 non-null   float64 \n",
      " 21  PerformanceRating         1470 non-null   category\n",
      " 22  RelationshipSatisfaction  1470 non-null   category\n",
      " 23  StockOptionLevel          1470 non-null   category\n",
      " 24  TotalWorkingYears         1470 non-null   float64 \n",
      " 25  TrainingTimesLastYear     1470 non-null   float64 \n",
      " 26  WorkLifeBalance           1470 non-null   category\n",
      " 27  YearsAtCompany            1470 non-null   float64 \n",
      " 28  YearsInCurrentRole        1470 non-null   float64 \n",
      " 29  YearsSinceLastPromotion   1470 non-null   float64 \n",
      " 30  YearsWithCurrManager      1470 non-null   float64 \n",
      " 31  first_company             1470 non-null   category\n",
      " 32  first_role                1470 non-null   category\n",
      " 33  first_manager             1470 non-null   category\n",
      "dtypes: category(13), float64(21)\n",
      "memory usage: 262.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    test_metric = \"auc\"\n",
    "    \n",
    "    param = {\n",
    "        # \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"eval_metric\": f\"{test_metric}\",\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0, 6),\n",
    "        # \"scale_pos_weight\": Counter(y)[0] / Counter(y)[1],\n",
    "        # \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 0, 10),\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\",\"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 10.0),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0, 10.0, ),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0, log=True),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.1, 1.0), \n",
    "        \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.1, 1.0), \n",
    "        \"sampling_method\": \"uniform\",  # uniform, gradient_based\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1, 50),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 10, 2000),\n",
    "        # \"num_parallel_tree\": trial.suggest_int(\"num_parallel_tree\", 0, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-8, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 10.0),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"depthwise\",\"lossguide\"]),\n",
    "    }\n",
    "\n",
    "    if param[\"grow_policy\"] == \"lossguide\":\n",
    "        param[\"max_leaves\"] = trial.suggest_int(\"max_leaves\", 1, 100)\n",
    "\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"sample_type\"] = \"uniform\"\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\",\"forest\"])\n",
    "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0)\n",
    "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0)\n",
    "        param[\"one_drop\"] = trial.suggest_categorical(\"one_drop\", [True,False])\n",
    "        \n",
    "    # pruning_callback = optuna.integration.XGBoostPruningCallback(trial, f\"validate-{test_metric}\")\n",
    "    clf = xgb.XGBClassifier(**param, n_estimators=10000, verbosity=0, enable_categorical=True)\n",
    "    selector = RFECV(clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10), cv=10, scoring=\"f1\")\n",
    "    \n",
    "    selector.fit(X_train, y_train)\n",
    "    y_pred = selector.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "# study.optimize(objective, n_trials=1000, n_jobs=1, show_progress_bar=True, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.56276\n",
      "[1]\tvalidation_0-logloss:0.49069\n",
      "[2]\tvalidation_0-logloss:0.44087\n",
      "[3]\tvalidation_0-logloss:0.41620\n",
      "[4]\tvalidation_0-logloss:0.38980\n",
      "[5]\tvalidation_0-logloss:0.36962\n",
      "[6]\tvalidation_0-logloss:0.36216\n",
      "[7]\tvalidation_0-logloss:0.35921\n",
      "[8]\tvalidation_0-logloss:0.35553\n",
      "[9]\tvalidation_0-logloss:0.35563\n",
      "[10]\tvalidation_0-logloss:0.36001\n",
      "[11]\tvalidation_0-logloss:0.35455\n",
      "[12]\tvalidation_0-logloss:0.35625\n",
      "[13]\tvalidation_0-logloss:0.35429\n",
      "[14]\tvalidation_0-logloss:0.35556\n",
      "[15]\tvalidation_0-logloss:0.35759\n",
      "[16]\tvalidation_0-logloss:0.35869\n",
      "[17]\tvalidation_0-logloss:0.35492\n",
      "[18]\tvalidation_0-logloss:0.35844\n",
      "[19]\tvalidation_0-logloss:0.36370\n",
      "[20]\tvalidation_0-logloss:0.36637\n",
      "[21]\tvalidation_0-logloss:0.36726\n",
      "[22]\tvalidation_0-logloss:0.36623\n",
      "[23]\tvalidation_0-logloss:0.37186\n",
      "[24]\tvalidation_0-logloss:0.37112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nicholas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\python-3_T6Md9L-py3.11\\Lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tvalidation_0-logloss:0.37145\n",
      "[26]\tvalidation_0-logloss:0.37595\n",
      "[27]\tvalidation_0-logloss:0.37598\n",
      "[28]\tvalidation_0-logloss:0.38001\n",
      "[29]\tvalidation_0-logloss:0.38199\n",
      "[30]\tvalidation_0-logloss:0.38516\n",
      "[31]\tvalidation_0-logloss:0.38879\n",
      "[32]\tvalidation_0-logloss:0.39063\n",
      "[33]\tvalidation_0-logloss:0.39122\n",
      "[34]\tvalidation_0-logloss:0.39326\n",
      "[35]\tvalidation_0-logloss:0.39106\n",
      "[36]\tvalidation_0-logloss:0.38926\n",
      "[37]\tvalidation_0-logloss:0.39394\n",
      "[38]\tvalidation_0-logloss:0.39712\n",
      "[39]\tvalidation_0-logloss:0.40019\n",
      "[40]\tvalidation_0-logloss:0.40122\n",
      "[41]\tvalidation_0-logloss:0.40232\n",
      "[42]\tvalidation_0-logloss:0.40397\n",
      "[43]\tvalidation_0-logloss:0.40465\n",
      "[44]\tvalidation_0-logloss:0.40776\n",
      "[45]\tvalidation_0-logloss:0.41037\n",
      "[46]\tvalidation_0-logloss:0.41201\n",
      "[47]\tvalidation_0-logloss:0.41353\n",
      "[48]\tvalidation_0-logloss:0.41196\n",
      "[49]\tvalidation_0-logloss:0.41128\n",
      "[50]\tvalidation_0-logloss:0.41428\n",
      "[51]\tvalidation_0-logloss:0.41820\n",
      "[52]\tvalidation_0-logloss:0.42110\n",
      "[53]\tvalidation_0-logloss:0.42128\n",
      "[54]\tvalidation_0-logloss:0.42198\n",
      "[55]\tvalidation_0-logloss:0.42121\n",
      "[56]\tvalidation_0-logloss:0.42384\n",
      "[57]\tvalidation_0-logloss:0.42508\n",
      "[58]\tvalidation_0-logloss:0.42625\n",
      "[59]\tvalidation_0-logloss:0.42534\n",
      "[60]\tvalidation_0-logloss:0.42466\n",
      "[61]\tvalidation_0-logloss:0.42651\n",
      "[62]\tvalidation_0-logloss:0.42948\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(tree_method=\"hist\" ,n_estimators=10000, enable_categorical=True, verbosity=1)\n",
    "clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50)\n",
    "# clf.set_params(early_stopping_rounds=10)\n",
    "rfe = RFECV(clf, cv=3, scoring=\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rfe\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\python-3_T6Md9L-py3.11\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:725\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    722\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[0;32m    723\u001b[0m     func \u001b[39m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m--> 725\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    726\u001b[0m     func(rfe, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y, train, test, scorer)\n\u001b[0;32m    727\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    728\u001b[0m )\n\u001b[0;32m    730\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n\u001b[0;32m    731\u001b[0m scores_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(scores, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\python-3_T6Md9L-py3.11\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:726\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    722\u001b[0m     parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n\u001b[0;32m    723\u001b[0m     func \u001b[39m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[0;32m    725\u001b[0m scores \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m--> 726\u001b[0m     func(rfe, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator, X, y, train, test, scorer)\n\u001b[0;32m    727\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    728\u001b[0m )\n\u001b[0;32m    730\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n\u001b[0;32m    731\u001b[0m scores_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(scores, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\python-3_T6Md9L-py3.11\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:37\u001b[0m, in \u001b[0;36m_rfe_single_fit\u001b[1;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[0;32m     35\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[0;32m     36\u001b[0m X_test, y_test \u001b[39m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m rfe\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m     38\u001b[0m     X_train,\n\u001b[0;32m     39\u001b[0m     y_train,\n\u001b[0;32m     40\u001b[0m     \u001b[39mlambda\u001b[39;49;00m estimator, features: _score(\n\u001b[0;32m     41\u001b[0m         estimator, X_test[:, features], y_test, scorer\n\u001b[0;32m     42\u001b[0m     ),\n\u001b[0;32m     43\u001b[0m )\u001b[39m.\u001b[39mscores_\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\python-3_T6Md9L-py3.11\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:299\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    297\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting estimator with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m features.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m np\u001b[39m.\u001b[39msum(support_))\n\u001b[1;32m--> 299\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X[:, features], y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    301\u001b[0m \u001b[39m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    302\u001b[0m importances \u001b[39m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    303\u001b[0m     estimator,\n\u001b[0;32m    304\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimportance_getter,\n\u001b[0;32m    305\u001b[0m     transform_func\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msquare\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    306\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\python-3_T6Md9L-py3.11\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\python-3_T6Md9L-py3.11\\Lib\\site-packages\\xgboost\\sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[0;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[1;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1491\u001b[0m     params,\n\u001b[0;32m   1492\u001b[0m     train_dmatrix,\n\u001b[0;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1502\u001b[0m )\n\u001b[0;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[0;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\python-3_T6Md9L-py3.11\\Lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\python-3_T6Md9L-py3.11\\Lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nicholas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\python-3_T6Md9L-py3.11\\Lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    # storage=storage,\n",
    "    # directions=[\"maximize\", \"minimize\"],\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"employee_data_f1_weighted\",\n",
    "    load_if_exists=True,\n",
    "    # sampler=optuna.samplers.MOTPESampler(),\n",
    "    # pruner=optuna.pruners.HyperbandPruner(),\n",
    "    # sampler=optuna.samplers.TPESampler(),\n",
    "    pruner=optuna.pruners.MedianPruner(),\n",
    "    sampler=optuna.samplers.RandomSampler()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=10000, show_progress_bar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3_T6Md9L-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
